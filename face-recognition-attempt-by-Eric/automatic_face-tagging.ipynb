{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the deliverables produced from this project: https://library.hkust.edu.hk/ds/project/p002/\n",
    "\n",
    "> This notebook is created by ZHANG Ka Ho Eric (Year 2 student, BEng in Electronic Engineering, HKUST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person = pd.read_csv('./newdb/tagPerson.csv')\n",
    "tagged_person_list = df_person.name[0], df_person.name[50], df_person.name[88]\n",
    "tagged_person_id_list = [0, 50, 88]\n",
    "# Chia-wei Woo (吳家瑋), Nancy IP (葉玉如), Paul CHU (朱經武)\n",
    "\n",
    "df_tag = pd.read_csv('./newdb/tag.csv')\n",
    "result_df = df_tag[df_tag['personID'] == 0].dropna() # check personID == 0\n",
    "# for i in tagged_person_id_list[1:]:\n",
    "#     df = df_tag[df_tag['personID'] == i].dropna()\n",
    "    \n",
    "#     result_df.add(df)\n",
    "#     df.reset_index(inplace=True)\n",
    "#     print(df.shape[0])\n",
    "# TO-do: add all tagged person into result_df\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "df_photo = pd.read_csv('./newdb/photo.csv')\n",
    "df_photo['image'] = df_photo[\"imagepath\"].map(lambda x: x.split('/')[2].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from website to:\n",
    "# 1. Save images to 'raw'\n",
    "# 2. crop and save images by the rectangle tagged boxes from database to 'test/unknown/rectangle'\n",
    "\n",
    "\n",
    "photo_ID_list = []\n",
    "for i in range(len(result_df)): #df_list[0] for Chia-wei Woo (吳家瑋)\n",
    "    id = result_df.loc[i, \"photoID\"]\n",
    "    aid = result_df.loc[i, \"albumID\"]\n",
    "    c1, c2, c3, c4 = (int(i) for i in result_df.iloc[i, -4:])\n",
    "    temp = df_photo[(df_photo['image'] == id) & (df_photo['aID'] == aid)]\n",
    "    if not temp.empty:\n",
    "        url = \"https://digitalimages.hkust.edu.hk/gallery/\"+temp['imagepath'].values[0].replace(' ', '%20')\n",
    "        with urllib.request.urlopen(url) as url:\n",
    "            s = url.read()\n",
    "        arr = np.asarray(bytearray(s), dtype=np.uint8)\n",
    "        img = cv2.imdecode(arr, -1) # 'Load it as it is'\n",
    "        cv2.imwrite('test/raw/'  + id + '.jpg', img)\n",
    "\n",
    "        c1 = int(c1 * (img.shape[1]/640))\n",
    "        c2 = int(c2 * (img.shape[1]/640))\n",
    "        c3 = int(c3 * (img.shape[1]/640))\n",
    "        c4 = int(c4 * (img.shape[1]/640))\n",
    "        cv2.rectangle(img, (c1, c2), (c1+c3, c2+c4), (0, 0, 255), 2) \n",
    "        face = img[c2:c2 + c4, c1:c1 + c3]\n",
    "        cv2.imwrite('test/unknown/rectangle/'  + id + \"_cropped.jpg\", face)\n",
    "        photo_ID_list.append([id +'.jpg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 5/5 [01:25<00:00, 17.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use face-crop-plus to crop images and save in in 'test/unknwon/face-crop-plus'\n",
    "\n",
    "\n",
    "from face_crop_plus import Cropper\n",
    "from torch.cuda import is_available\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "INPUT_DIR = os.path.join(current_directory, \"test/raw\")\n",
    "OUTPUT_DIR = os.path.join(current_directory, \"test/unknown/face-crop-plus\")\n",
    "\n",
    "# Set all to False if running on CPU (unless you can wait for a bit)\n",
    "TEST_QUALITY_ENHANCEMENT = False\n",
    "TEST_ATTR_GROUPING = False\n",
    "TEST_MASK_GROUPING = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize as None\n",
    "    enh_threshold = None\n",
    "    attr_groups = None\n",
    "    mask_groups = None\n",
    "\n",
    "    if TEST_QUALITY_ENHANCEMENT:\n",
    "        enh_threshold = 0.001\n",
    "\n",
    "    if TEST_ATTR_GROUPING:\n",
    "        attr_groups = {\"faces_features\": [2, 3, 4, 5, 7, 8, 10, 11]}\n",
    "    \n",
    "    if TEST_MASK_GROUPING:\n",
    "        mask_groups = {\"hat and eyeglasses\": [6, 18], \"no_accessories\": [-9, -15, -18]}\n",
    "\n",
    "    # Initialize cropper\n",
    "    cropper = Cropper(\n",
    "        output_size=(256, 256),\n",
    "        output_format=\"jpg\",\n",
    "        face_factor=0.725,\n",
    "        strategy=\"all\",\n",
    "        device = \"cuda:0\" if is_available() else \"cpu\",\n",
    "        enh_threshold=enh_threshold,\n",
    "        attr_groups=attr_groups,\n",
    "        mask_groups=mask_groups,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Process images in the input dir and save face images to output dir\n",
    "    cropper.process_dir(input_dir=INPUT_DIR, output_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TO-do: select img_path in unknown / raw to iterately check all people in knwon\n",
    "\n",
    "# Note: deepface would automatically detect one face in an image\n",
    "\n",
    "# --> find out which face would be detected --> take x y width height corrdinates\n",
    "\n",
    "# Output: save and cropped the detected images in output\n",
    "# 1: the unknown image was considered as the corresponding known sample image after the process of deepface model\n",
    "# 0: the unknown image was not considered as the corresponding known sample image after the process of deepface model \n",
    "# OR\n",
    "# 0: the unknown image was fail to process the deepface model because of imcompleted face features such as side-face and masked face\n",
    "\n",
    "result = \"try\"\n",
    "model_name = 'Facenet'\n",
    "known_path = \"known\"\n",
    "unknown_path = \"test/unknown/face-crop-plus\"\n",
    "known_images = os.listdir(\"known\")\n",
    "\n",
    "\n",
    "output = []\n",
    "for unknown_img in os.listdir(unknown_path):\n",
    "    img2_path = unknown_path + '/' + unknown_img\n",
    "    member_check = []\n",
    "    for known_img in os.listdir(known_path):\n",
    "        img1_path = known_path + '/' + known_img\n",
    "        try:\n",
    "            result = DeepFace.verify(img1_path = img1_path, img2_path = img2_path, model_name = model_name)\n",
    "            member_check.append(int(result[\"verified\"]))\n",
    "        except:\n",
    "            member_check.append(0)\n",
    "    y_pred = np.array(member_check)\n",
    "    member_check.insert(0, unknown_img)\n",
    "    if(\"-NG\" in unknown_img):\n",
    "        y_true = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0])  \n",
    "    else:\n",
    "        y_true = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    member_check.append(f1_score(y_true, y_pred, average = 'macro'))\n",
    "    output.append(member_check)\n",
    "    print(member_check)\n",
    "\n",
    "known_images.insert(0, \"unknwon_image\")\n",
    "known_images.append(\"F1-score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9042"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output, photo_ID_list, result_df, df_photo, df_person, df_tag\n",
    "len(output[0]) * len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trun output into csv file\n",
    "\n",
    "output.pop(0)\n",
    "ans = pd.DataFrame(output)\n",
    "ans.set_axis(known_images, axis=\"columns\")\n",
    "\n",
    "ans.to_csv(\"test-output.csv\", index=False, header=known_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n"
     ]
    }
   ],
   "source": [
    "# finding positive img and negative img\n",
    "\n",
    "positive_img = []\n",
    "for unknown_img in output:\n",
    "    for check_index in range(len(unknown_img)):\n",
    "        if unknown_img[check_index] == True and check_index >= 23 and check_index <= 25:\n",
    "            positive_img.append(unknown_img[0])\n",
    "            img = cv2.imread(\"test/unknown/face-crop-plus/\" + unknown_img[0])\n",
    "            cv2.imwrite('output/target/'  + unknown_img[0], img)\n",
    "\n",
    "positive_img\n",
    "\n",
    "negative_img = os.listdir(\"test/unknown/face-crop-plus\")\n",
    "print(len(negative_img) - 23 - 20 - 40)\n",
    "\n",
    "#     P   N\n",
    "# T   23  20\n",
    "# F   40  191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using another model (encoding also) to do face recognition\n",
    "\n",
    "\n",
    "import face_recognition\n",
    "\n",
    "def read_img(path):\n",
    "    img = cv2.imread(path)\n",
    "    (h, w) = img.shape[:2]\n",
    "    width = 500\n",
    "    ratio = width / float(w)\n",
    "    height = int(h * ratio)\n",
    "    return cv2.resize(img, (width, height))\n",
    "\n",
    "\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "known_encodings = []\n",
    "known_names = []\n",
    "known_dir = 'known' # +  '/' + tagged_person\n",
    "for file in os.listdir(known_dir):\n",
    "  img = read_img(known_dir + '/' + file)\n",
    "  img_enc = face_recognition.face_encodings(img)[0]\n",
    "  known_encodings.append(img_enc)\n",
    "  known_names.append(file.split('.')[0])\n",
    "\n",
    "unknown_dir = 'test/unknown/face-crop-plus'\n",
    "for file in os.listdir(unknown_dir):\n",
    "  # print(\"Processing\", file)\n",
    "  img = read_img(unknown_dir + '/' + file)\n",
    "  img_enc = face_recognition.face_encodings(img)\n",
    "  if(img_enc == []):\n",
    "    acc_list.append(0)\n",
    "    continue\n",
    "\n",
    "  results = face_recognition.compare_faces(known_encodings, img_enc[0])\n",
    "  accuracy = np.sum(np.array(results)) / len(results)\n",
    "  if(accuracy > 0.75): # change\n",
    "    acc_list.append(1)\n",
    "  else:\n",
    "    acc_list.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_person = tagged_person_list[0][:-6] # @@@replace with@@@ for tagged_person in tagged_person_list: \n",
    "\n",
    "record_list = []\n",
    "for index in range(len(photo_ID_list)):\n",
    "    file_name = photo_ID_list[index][0]\n",
    "    cropped_file_name = file_name[:-4] +  '_cropped' + '.jpg'\n",
    "    correct = acc_list[index]\n",
    "    if correct:\n",
    "        detected_person = tagged_person\n",
    "    else:\n",
    "        detected_person = 0\n",
    "    record_list.append([file_name, tagged_person, cropped_file_name, detected_person, correct])\n",
    "\n",
    "result = pd.DataFrame(record_list)\n",
    "result.to_csv(\"face-recognition_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output all image in website with important ust members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all images from website to:\n",
    "# 1. Save images to 'raw'\n",
    "# 2. crop and save images by the rectangle tagged boxes from database to 'unknown/rectangle'\n",
    "\n",
    "# @@@@@ TO BE IMPLEMENTED @@@@@\n",
    "\n",
    "result_df = df_tag\n",
    "for i in range(len(result_df)): #df_list[0] for Chia-wei Woo (吳家瑋)\n",
    "    id = result_df.loc[i, \"photoID\"]\n",
    "    aid = result_df.loc[i, \"albumID\"]\n",
    "    temp = df_photo[(df_photo['image'] == id) & (df_photo['aID'] == aid)]\n",
    "    if not temp.empty:\n",
    "        url = \"https://digitalimages.hkust.edu.hk/gallery/\"+temp['imagepath'].values[0].replace(' ', '%20')\n",
    "        with urllib.request.urlopen(url) as url:\n",
    "            s = url.read()\n",
    "        arr = np.asarray(bytearray(s), dtype=np.uint8)\n",
    "        img = cv2.imdecode(arr, -1) # 'Load it as it is'\n",
    "        cv2.imwrite('raw/'  + id + '.jpg', img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageTag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
