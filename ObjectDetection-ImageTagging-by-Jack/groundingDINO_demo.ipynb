{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the deliverables produced from this project: https://library.hkust.edu.hk/ds/project/p002/\n",
    "> Created by LAU Ming Kit, Jack (Year 4 student, BEng in Computer Engineering, HKUST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroundingDINO demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, cv2, copy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from torchvision.ops import box_convert\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# RAM\n",
    "from PIL import Image\n",
    "from ram.models import ram_plus\n",
    "from ram import inference_ram as inference\n",
    "from ram import get_transform\n",
    "\n",
    "# Grounding DINO\n",
    "import groundingdino.datasets.transforms as T\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util import box_ops\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "from segment_anything import build_sam, SamPredictor \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hugging face\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "## Follow instruction on https://github.com/IDEA-Research/GroundingDINOg if you encounter any difficulties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable\n",
    "image_path = \"images/MED_VIN_004SM.jpg\" # Change this can be path or image \"images\"\n",
    "output_file = \"output\"  # specify the output dir\n",
    "TEXT_PROMPT = \"\"   # Change the text prompt for different detection object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global function\n",
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "            cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "            args = SLConfig.fromfile(cache_config_file) \n",
    "            model = build_model(args)\n",
    "            args.device = device\n",
    "\n",
    "            cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "            checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "            log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "            print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "            _ = model.eval()\n",
    "            return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
    "\n",
    "groundingdino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_TRESHOLD = 0.3\n",
    "TEXT_TRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byfile(image_path):\n",
    "    image_source, image = load_image(image_path)\n",
    "\n",
    "    boxes, logits, phrases = predict(\n",
    "    model=groundingdino_model, \n",
    "    image=image, \n",
    "    caption=TEXT_PROMPT, \n",
    "    box_threshold=BOX_TRESHOLD, \n",
    "    text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "\n",
    "    annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "    #annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "\n",
    "\n",
    "    cv2.imwrite(output_file+'/'+image_path, annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byfolder(input_file):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # download the model from the URL below and put in the \"pretrained\" folder of your working directory \n",
    "    # https://huggingface.co/xinyu1205/recognize-anything-plus-model/resolve/main/ram_plus_swin_large_14m.pth\n",
    "    ram_pth =  \"pretrained/ram_plus_swin_large_14m.pth\"\n",
    "    image_size = 384\n",
    "    transform = get_transform(image_size=image_size)\n",
    "\n",
    "    # load ram model\n",
    "    model = ram_plus(pretrained=ram_pth,\n",
    "                                image_size=image_size,\n",
    "                                vit='swin_l')\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for i in os.listdir(input_file):\n",
    "        if (i[-3:] == \"jpg\" or i[-3:] == \"png\"):   \n",
    "            image_path = input_file+'/'+i\n",
    "            ori_image = Image.open(image_path)\n",
    "            image = transform(ori_image).unsqueeze(0).to(device)\n",
    "            res = inference(image, model)\n",
    "            \n",
    "            print(\"Image Tags: \", res[0])\n",
    "            print(res[0].replace(\"|\", \".\")+' .')\n",
    "            \n",
    "            TEXT_PROMPT = res[0].replace(\"|\", \".\")+' .'\n",
    "            BOX_TRESHOLD = 0.3\n",
    "            TEXT_TRESHOLD = 0.25\n",
    "\n",
    "            image_source, image = load_image(image_path)\n",
    "\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=groundingdino_model, \n",
    "                image=image, \n",
    "                caption=TEXT_PROMPT, \n",
    "                box_threshold=BOX_TRESHOLD, \n",
    "                text_threshold=TEXT_TRESHOLD\n",
    "            )\n",
    "\n",
    "            print(\"boxes=\",boxes)\n",
    "            print(\"logits=\",logits)\n",
    "            print(\"phrases=\",phrases)\n",
    "\n",
    "            annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "            #annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "            cv2.imwrite(output_file+'/boxes_'+i, annotated_frame)\n",
    "            print(\"image saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(image_path) <= 3:\n",
    "    byfolder(image_path)\n",
    "elif image_path[-3:] == 'png' or image_path[-3:] == 'jpg' or image_path[-4:] == 'jpeg':\n",
    "    byfile(image_path)\n",
    "elif '.' in image_path:\n",
    "    print('wrong file type')\n",
    "else:\n",
    "    byfolder(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageTag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
